# -*- coding: utf-8 -*-
"""Untitled27.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x1OPkTmhpbMYTo2LsWwpCL5EUkP4BxUN
"""

import pandas as pd
import numpy as np
from tqdm import tqdm
df=pd.read_csv('test.csv')
#print(df.head())
user_ids=df.user_id.unique()
#print(len(user_ids))
total_challenges=df.user_sequence.count()
df_id=pd.DataFrame()
df_id['index']=[i for i in range(0,len(user_ids))]
df_id['id']=np.nan
for count,rows in enumerate(df_id.index):
	df_id['id'][count]=user_ids[count]
df_id.drop(['index'],1,inplace=True)

rows_processed=0
for i in range(1,14):
	df_id['challenge_{}'.format(i)]=np.nan

for count,rows in (enumerate(df['challenge'])):
	userid=df.user_sequence[count].split("_")[0]
	challenge_seq=df.user_sequence[count].split("_")[1]
	
	for counter,ids in (enumerate(df_id['id'])):
	 if ids==int(userid):
		 #print(count) 
		 #print(df['challenge'][df.index])
		 #print('processing ',counter ,' for id ',ids)
		 df_id['challenge_{}'.format(challenge_seq)][counter]=df['challenge'][count]
		 '''print(df_id.head())'''
		 rows_processed+=1
		 if rows_processed%10000==0:
		 	print('{} rows processed out of {} => {}%'.format(rows_processed,total_challenges,(rows_processed*100)/total_challenges))
	 	
		 break
	 	
df_id.to_csv('tester_challenges.csv',index=False)

df=pd.read_csv('safe.csv')

def handle_non_numeric_data(df):
	columns=df.columns.values
	#print(columns)
	for column in columns:
		text_digit_vals={}
		def convert_to_int(val):
			return text_digit_vals[val]
		if df[column].dtype!=np.int64 and df[column].dtype!=np.float64:
			column_contents=df[column].values.tolist()
			unique_elements=set(column_contents)

			x=0
			for unique in unique_elements:
				if unique not in text_digit_vals:
					text_digit_vals[unique]=x
					x+=1

			df[column]=list(map(convert_to_int,df[column]))
	#df.to_csv('finale.csv',index=False)
	return df

df=handle_non_numeric_data(df)
print(df.head())
df.drop(['challenge_12','challenge_13','id'],1,inplace=True)
x=np.array(df.drop(['challenge_11'],1).astype(float))
#print(x)
#x=preprocessing.scale(x)
#print(x)
y=np.array(df.challenge_11)
from xgboost import XGBRegressor
from sklearn.model_selection import train_test_split
xgb11=XGBRegressor(n_estimators=1000)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1)
xgb11.fit(x,y)
accuracy=xgb11.score(x_test,y_test)
print(accuracy)

!unzip 'train.zip'

df_train=pd.read_csv('tester_challenges.csv')
columns=[ 'challenge_1', 'challenge_2' ,'challenge_3', 'challenge_4',
 'challenge_5' ,'challenge_6', 'challenge_7' ,'challenge_8' ,'challenge_9',
 'challenge_10']
#print(columns)
for column in columns:
    for count,rows in enumerate(df_train[column]):
        df_train[column][count]=rows.split("I")[-1]
        print(column, " being processed", df_train[column][count])
df_train.to_csv('preprocessed_test.csv',index=False)

df_use=pd.read_csv('preprocessed.csv')
print(df_use.head())
df_use.drop(['challenge_12','challenge_13','id'],1,inplace=True)
x=np.array(df_use.drop(['challenge_11'],1).astype(float))
#print(x)
#x=preprocessing.scale(x)
#print(x)
y=np.array(df_use.challenge_11)
from xgboost import XGBRegressor,plot_importance
from sklearn import svm
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
hyperparams={'max_depth':10, 'n_estimators':1000}
xgb_11=XGBRegressor(max_depth=10,n_estimators=1000)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1)
xgb_11.fit(x,y)
accuracy=xgb_11.score(x_test,y_test)
print(accuracy)
plot_importance(xgb_11)
#print(x)
plt.show()

'''GBR=XGBRegressor()
search_grid={'n_estimators':[1000],'learning_rate':[0.1],'max_depth':range(1,9,1)}
search=GridSearchCV(estimator=GBR,param_grid=search_grid,scoring='neg_mean_squared_error',n_jobs=-1)
search.fit(x_train,y_train)
print(search.best_params_)
'''

df_use=pd.read_csv('preprocessed.csv')
print(df_use.head())
df_use.drop(['challenge_11','challenge_13','id'],1,inplace=True)
x=np.array(df_use.drop(['challenge_12'],1).astype(float))
#print(x)
#x=preprocessing.scale(x)
#print(x)
y=np.array(df_use.challenge_12)

xgb_12=XGBRegressor(n_estimators=1000,max_depth=10)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1)
xgb_12.fit(x,y)
accuracy=xgb_12.score(x_test,y_test)
print(accuracy)
plot_importance(xgb_12)
#print(x)
plt.show()

df_use=pd.read_csv('preprocessed.csv')
print(df_use.head())
df_use.drop(['id'],1,inplace=True)
x=np.array(df_use.drop(['challenge_13','challenge_12','challenge_11'],1).astype(float))
#print(x)
#x=preprocessing.scale(x)
#print(x)
y=np.array(df_use.challenge_13)

xgb_13=XGBRegressor(n_estimators=1000,max_depth=10)
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.1)
xgb_13.fit(x,y)
accuracy=xgb_13.score(x_test,y_test)
print(accuracy)
plot_importance(xgb_13)
#print(x)
plt.show()

!unzip "test.zip"

df_test=pd.read_csv('preprocessed_test.csv')
#print(df_test.head())
with open('recommendation-submission.csv','w') as f:
    f.write('user_sequence,challenge\n')
for iterator,rows in tqdm(enumerate(df_test['id'])):
    lister=[]
    twister=[]
    barrister=[]
    for i in range(1,11):
        
        lister.append(df_test["challenge_{}".format(i)][iterator])
        
    
    with open('recommendation-submission.csv','a') as f:
        f.write("{}_11,CI{}\n".format(int(rows),int(xgb_11.predict(lister))))
        f.write("{}_12,CI{}\n".format(int(rows),int(xgb_12.predict(lister))))
        f.write("{}_13,CI{}\n".format(int(rows),int(xgb_13.predict(lister))))
    #print(int(rows),int(xgb_11.predict(lister)),int(xgb_12.predict(lister)),int(xgb_13.predict(lister)))

df=pd.read_csv('challenge_data.csv')
#print(df.head())
df_train=pd.read_csv('preprocessed.csv')
columns=[ 'challenge_1', 'challenge_2' ,'challenge_3', 'challenge_4',
 'challenge_5' ,'challenge_6', 'challenge_7' ,'challenge_8' ,'challenge_9',
 'challenge_10',
 'challenge_11',
 'challenge_12',
 'challenge_13']
for i in range(1,14):
    df_train['challenge_{}_lang'.format(i)]=0
for colno,column in enumerate(columns):
    for iter,rows in enumerate(df_train[column]):
        for counter,values in enumerate(df['challenge_ID']):
            if int(values.split("I")[-1])==rows:
                #print(df['programming_language'][counter])
                df_train['challenge_{}_lang'.format(colno+1)][iter]=df['programming_language'][counter]
                print('Processing column {}'.format(column))

df_train.to_csv('lang.csv',index=False)